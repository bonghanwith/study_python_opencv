{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Support Vector Machines (SVM)](https://docs.opencv.org/3.4/d3/d02/tutorial_py_svm_index.html)\n",
    "Understand concepts of SVM\n",
    "\n",
    "### [Understanding SVM](https://docs.opencv.org/3.4/d4/db1/tutorial_py_svm_basics.html)\n",
    "Get a basic understanding of what SVM is\n",
    "\n",
    "#### Goal\n",
    "In this chapter\n",
    "\n",
    "* We will see an intuitive understanding of SVM\n",
    "\n",
    "#### Theory\n",
    "\n",
    "##### 선형 분리 가능 데이터\n",
    "적색과 청색의 두 가지 유형의 데이터가있는 아래 이미지를 고려하십시오. kNN에서 테스트 데이터의 경우 모든 훈련 샘플까지의 거리를 측정하고 최소 거리를 사용했습니다. 모든 훈련 샘플을 저장하기 위해 모든 거리와 충분한 메모리를 측정하는 데는 많은 시간이 필요합니다. 그러나 이미지에서 주어진 데이터를 고려할 때 우리는 그만큼 많이 필요합니까?\n",
    "\n",
    "![](svm_basics1.png)\n",
    "\n",
    "또 다른 아이디어를 생각해보십시오. 두 데이터를 두 영역으로 나누는 \\\\(f(x)=ax_1+bx_2+c\\\\) 행을 찾습니다. 새로운 test_data X를 얻었을 때 \\\\(f(x)\\\\)로 대치하면됩니다. \\\\(f(X) > 0\\\\)이면 파란색 그룹에 속하며 그렇지 않으면 빨간색 그룹에 속합니다. 이 선을 **결정 경계(Decision Boundary)**라고 부를 수 있습니다. 그것은 매우 간단하고 메모리 효율적입니다. 직선 (또는 더 높은 차원의 초평면)으로 2로 나눌 수있는 이러한 데이터를 **선형 분리 가능**이라고 합니다.\n",
    "\n",
    "그래서 위의 이미지에서, 당신은 그러한 선들이 많이 있음을 볼 수 있습니다. 어느 쪽을 택할 것입니까? 매우 직관적으로 우리는 라인이 가능한 모든 포인트에서 지나가야한다고 말할 수 있습니다. 왜? 들어오는 데이터에 잡음이있을 수 있기 때문입니다. 이 데이터는 분류 정확도에 영향을 주어서는 안됩니다. 따라서 가장 먼 선을 사용하면 노이즈에 대한 내성이 향상됩니다. SVM이하는 일은 훈련 샘플에 대한 최소 거리가 가장 긴 직선 (또는 초평면)을 찾는 것입니다. 가운데를 지나가는 아래 그림의 굵은 선을보십시오.\n",
    "\n",
    "![](svm_basics2.png)\n",
    "\n",
    "따라서이 결정 경계를 찾으려면 교육 데이터가 필요합니다. 모두 필요햘까요? 아니에요. 반대편 그룹에 가까운 것만으로 충분합니다. 우리의 이미지에서, 그들은 하나의 파란색으로 채워진 원과 두 개의 빨간색으로 채워진 사각형입니다. **지원 벡터(Support Vector)**라고 부를 수 있으며, 이를 통과하는 선을 **지원 평면 (Support Planes)**이라고 합니다. 그것들은 우리의 의사 결정 경계를 찾는 데 적합 합니다. 우리는 모든 데이터에 대해 걱정할 필요가 없습니다. 데이터 축소에 도움이 됩니다.\n",
    "\n",
    "무슨 일이 있었는지, 데이터를 가장 잘 나타내는 처음 두 개의 초평면이 발견됩니다. 예를 들어, 청색 데이터는 \\\\(w^Tx+b_0 > 1\\\\)로 표현되고, 적색 데이터는 \\\\(w^Tx+b_0 < -1 \\\\)로 표현되며, w는 **가중치 벡터** (\\\\(w=[w_1, w_2,..., w_n]\\\\))이고 x는 피쳐 벡터 (\\\\(x = [x_1,x_2,..., x_n] \\\\)). \\\\(b_0\\\\)는 바이어스이다. 가중치 벡터는 바이어스 포인트가 위치를 결정하는 동안 결정 경계의 방향을 결정합니다. 이제 결정 경계는 이러한 초평면의 중간이되도록 정의되며, 따라서\\\\(w^Tx+b_0 = 0 \\\\)으로 표현됩니다. 지원 벡터에서 결정 경계까지의 최소 거리는 \\\\(distance_{support \\, vectors}=\\frac{1}{||w||}\\\\)로 주어진다. 여백은 이 거리의 두 배이며 이 여백을 최대화해야합니다. 즉, 다음과 같이 표현 될 수있는 몇 가지 제약 조건을 가지고 새로운 함수 \\\\(L(w, b_0) \\\\)를 최소화 할 필요가 있습니다.\n",
    "\n",
    "\\\\(\\min_{w, b_0} L(w, b_0) = \\frac{1}{2}||w||^2 \\; \\text{subject to} \\; t_i(w^Tx+b_0) \\geq 1 \\; \\forall i \\\\)\n",
    "\n",
    "where \\\\(t_i\\\\) is the label of each class, \\\\(t_i \\in [-1,1]\\\\)\n",
    "\n",
    "##### Non-Linearly Separable Data\n",
    "직선으로 2 개로 나눌 수없는 일부 데이터를 고려하십시오. 예를 들어 'X'가 -3 & +3에 있고 'O'가 -1 & +1에있는 1 차원 데이터를 생각해보십시오. 분명히 선형으로 분리 할 수 없습니다. 그러나 이러한 종류의 문제를 해결할 수있는 방법이 있습니다. 이 데이터 세트를 함수 \\\\(f(x) = x^2\\\\)로 매핑 할 수 있다면 9에서 'X'를 얻고 1에서 선형 분리가 가능한 'O'를 얻습니다.\n",
    "\n",
    "그렇지 않으면이 1 차원 데이터를 2 차원 데이터로 변환 할 수 있습니다. \\\\(f(x) =(x, x^2)\\\\) 함수를 사용하여 이 데이터를 매핑 할 수 있습니다. 그러면 'X'는 (-3,9)과 (3,9)이되고 'O'는 (-1,1)과 (1,1)이됩니다. 이것은 또한 선형 분리 가능합니다. 즉, 저 차원 공간에서의 비선형 분리 가능 데이터가 고차원 공간에서 선형 분리 가능하게 될 확률이 더 높습니다.\n",
    "\n",
    "일반적으로 선형 분리 가능성의 가능성을 확인하기 위해 d 차원 공간의 점을 일부 D 차원 공간 (D> d)에 매핑하는 것이 가능합니다. 저 차원 입력 (특징) 공간에서 계산을 수행하여 고차원 (커널) 공간에서 내적을 계산하는 데 도움이되는 아이디어가 있습니다. 다음 예를 통해 설명 할 수 있습니다.\n",
    "\n",
    "\n",
    "2 차원 공간에서 \\\\(p = (p_1, p_2)\\\\) 및 \\\\(q = (q_1, q_2)\\\\)의 두 점을 고려하십시오. \\\\(\\phi)를 다음과 같이 2 차원 점을 3 차원 공간에 매핑하는 매핑 함수라고 합시다.\n",
    "\\\\( \\phi (p) = (p_{1}^2,p_{2}^2,\\sqrt{2} p_1 p_2) \\phi (q) = (q_{1}^2,q_{2}^2,\\sqrt{2} q_1 q_2) \\\\)\n",
    "\n",
    "커널 함수 \\\\( K(p, q) \\\\)를 다음과 같이 두 점 사이의 내적 함수를 정의 합니다..\n",
    "\\\\( \\begin{aligned} K(p,q) = \\phi(p).\\phi(q) &= \\phi(p)^T \\phi(q) \\\\ &= (p_{1}^2,p_{2}^2,\\sqrt{2} p_1 p_2).(q_{1}^2,q_{2}^2,\\sqrt{2} q_1 q_2) \\\\ &= p_1 q_1 + p_2 q_2 + 2 p_1 q_1 p_2 q_2 \\\\ &= (p_1 q_1 + p_2 q_2)^2 \\\\ \\phi(p).\\phi(q) &= (p.q)^2 \\end{aligned} \\\\)\n",
    "\n",
    "이는 2 차원 공간에서 제곱 된 내적을 사용하여 3 차원 공간에서의 내적을 얻을 수 있음을 의미합니다. 이것은 고차원 공간에 적용될 수 있습니다. 따라서 우리는 더 낮은 차원 자체에서 더 높은 차원의 피처를 계산할 수 있습니다. 일단 우리가 그들을 매핑하면, 우리는 더 높은 차원 공간을 얻습니다.\n",
    "\n",
    "이러한 모든 개념 외에도 오 분류의 문제가 있습니다. 따라서 최대 마진으로 결정 경계를 찾는 것만으로는 충분하지 않습니다. 오 분류 오류의 문제도 고려해야 합니다. 가끔 마진이 적은 의사 결정 경계를 찾을 수는 있지만 오 분류가 줄어들 수 있습니다. 어쨌든 우리는 모델을 수정하여 최대 마진을 가진 의사 결정 경계를 찾아야하지만 오 분류는 적게해야 합니다. 최소화 기준은 다음과 같이 수정됩니다.\n",
    "\n",
    "\\\\( min \\; ||w||^2 + C(distance \\; of \\; misclassified \\; samples \\; to \\; their \\; correct \\; regions) \\\\)\n",
    "\n",
    "아래 이미지는 이 개념을 보여줍니다. 훈련 데이터의 각 샘플에 대해 새로운 매개 변수 \\\\(\\xi_i)가 정의됩니다. 해당 교육 샘플에서 올바른 결정 영역까지의 거리입니다. 잘못 분류되지 않은 사람들은 대응하는 지원 비행기에 떨어지므로 거리가 제로입니다.\n",
    "\n",
    "![](svm_basics3.png)\n",
    "따라서 새로운 최적화 문제는 다음과 같습니다.\n",
    "\\\\(\\min_{w, b_{0}} L(w,b_0) = ||w||^{2} + C \\sum_{i} {\\xi_{i}} \\text{ subject to } y_{i}(w^{T} x_{i} + b_{0}) \\geq 1 - \\xi_{i} \\text{ and } \\xi_{i} \\geq 0 \\text{ } \\forall i\\\\)\n",
    "\n",
    "\n",
    "매개 변수 C는 어떻게 선택해야합니까? 이 질문에 대한 대답은 교육 자료가 어떻게 배포되는지에 달려 있습니다. 일반적인 대답은 없지만 다음 규칙을 고려하는 것이 좋습니다.\n",
    "\n",
    "* C 값이 클수록 잘못된 분류 오류는 적지 만 마진은 작은 솔루션을 제공합니다. 이 경우 잘못 분류하는 데 비용이 많이 드는 것을 고려하십시오. 최적화의 목적은 인수를 최소화하기위한 것이므로 잘못된 분류 오류는 거의 허용되지 않습니다.\n",
    "* C 값이 작 으면 큰 여백과 더 많은 분류 오류가있는 솔루션을 제공합니다. 이 경우 최소화는 합계의 기간을 그렇게 고려하지 않으므로 큰 마진을 가진 초평면을 찾는 데 더 중점을 둡니다.\n",
    "\n",
    "#### Additional Resources\n",
    "\n",
    "[NPTEL notes on Statistical Pattern Recognition, Chapters 25-29.](https://nptel.ac.in/courses/106108057/26)\n",
    "\n",
    "#### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR of Hand-written Data using SVM\n",
    "Let's use SVM functionalities in OpenCV\n",
    "\n",
    "#### Goal\n",
    "In this chapter\n",
    "\n",
    "* We will revisit the hand-written data OCR, but, with SVM instead of kNN.\n",
    "\n",
    "#### OCR of Hand-written Digits\n",
    "kNN에서 우리는 직접 픽셀 강도를 피쳐 벡터로 사용했습니다. 이번에는 HOG ([Histogram of Oriented Gradients](https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients))를 특징 벡터로 사용하겠습니다.\n",
    "\n",
    "여기서 HOG를 찾기 전에 2 차 모멘트를 사용하여 이미지를 왜곡합니다. 그래서 우리는 처음 에 자릿수 이미지를 취하여 기울어 짐을 방지 하는 함수 deskew ()를 정의 합니다. 다음은 deskew() 함수입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deskew(img):\n",
    "    m = cv.moments(img)\n",
    "    if abs(m['mu02']) < 1e-2:\n",
    "        return img.copy()\n",
    "    skew = m['mu11'] / m['mu02']\n",
    "    M = np.float32([[1, skew, - 0.5 * SZ * skew], [0, 1, 0]])\n",
    "    img = cv.warpAffine(img, M, (SZ, SZ), flags=affine_flags)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 이미지는 0의 이미지에 적용된 디스 큐 기능 위를 보여줍니다. 왼쪽 이미지는 원본 이미지이고 오른쪽 이미지는 기울기 조정 이미지입니다.\n",
    "\n",
    "![](deskew.jpg)\n",
    "\n",
    "다음으로 각 세포의 HOG 디스크립터를 찾아야한다. 이를 위해 각 세포의 소벨 (Sobel) 유도체를 X, Y 방향으로 구합니다. 그런 다음 각 픽셀에서 그 크기와 기울기의 방향을 찾으십시오. 이 그래디언트는 16 개의 정수 값으로 양자화됩니다. 이 이미지를 네 개의 서브 스퀘어로 나눕니다. 각 부분 사각형에 대해 크기의 가중치가 적용된 방향 막대 그래프 (16 개 저장소)를 계산합니다. 따라서 각각의 서브 - 스퀘어는 16 개의 값을 포함하는 벡터를 제공합니다. 이러한 4 개의 벡터 (4 개의 서브 스퀘어)는 함께 64 개의 값을 포함하는 피쳐 벡터를 제공합니다. 이것은 우리가 데이터를 훈련 시키는데 사용하는 특징 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog(img):\n",
    "    gx        = cv.Sobel(img, cv.CV_32F, 1, 0)\n",
    "    gy        = cv.Sobel(img, cv.CV_32F, 0, 1)\n",
    "    mag, ang  = cv.cartToPolar(gx, gy)\n",
    "    bins      = np.int32(bin_n * ang / (2 * np.pi))    # quantizing binvalues in (0...16)\n",
    "    bin_cells = bins[:10, :10], bins[10:, :10], bins[:10, 10:], bins[10:, 10:]\n",
    "    mag_cells = mag[:10,: 10], mag[10:,: 10], mag[:10, 10:], mag[10:, 10:]\n",
    "    hists     = [np.bincount(b.ravel(), m.ravel(), bin_n) for b, m in zip(bin_cells, mag_cells)]\n",
    "    hist      = np.hstack(hists)     # hist is a 64 bit vector\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 이전 사례와 마찬가지로 큰 데이터 세트를 개별 셀로 분할합니다. 모든 자릿수에 대해 250 개의 셀이 학습 데이터 용으로 예약되어 있으며 나머지 250 개의 데이터는 테스트 용으로 예약되어 있습니다. 전체 코드는 아래에서 제공되며 여기 에서 다운로드 할 수도 있습니다 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.8\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "SZ           = 20\n",
    "bin_n        = 16 # Number of bins\n",
    "affine_flags = cv.WARP_INVERSE_MAP|cv.INTER_LINEAR\n",
    "\n",
    "def deskew(img):\n",
    "    m = cv.moments(img)\n",
    "    if abs(m['mu02']) < 1e-2:\n",
    "        return img.copy()\n",
    "    skew = m['mu11'] / m['mu02']\n",
    "    M = np.float32([[1, skew, - 0.5 * SZ * skew], [0, 1, 0]])\n",
    "    img = cv.warpAffine(img, M, (SZ, SZ), flags=affine_flags)\n",
    "    return img\n",
    "\n",
    "def hog(img):\n",
    "    gx        = cv.Sobel(img, cv.CV_32F, 1, 0)\n",
    "    gy        = cv.Sobel(img, cv.CV_32F, 0, 1)\n",
    "    mag, ang  = cv.cartToPolar(gx, gy)\n",
    "    bins      = np.int32(bin_n * ang / (2 * np.pi))    # quantizing binvalues in (0...16)\n",
    "    bin_cells = bins[:10, :10], bins[10:, :10], bins[:10, 10:], bins[10:, 10:]\n",
    "    mag_cells = mag[:10,: 10], mag[10:,: 10], mag[:10, 10:], mag[10:, 10:]\n",
    "    hists     = [np.bincount(b.ravel(), m.ravel(), bin_n) for b, m in zip(bin_cells, mag_cells)]\n",
    "    hist      = np.hstack(hists)     # hist is a 64 bit vector\n",
    "    return hist\n",
    "\n",
    "img = cv.imread('../data/digits.png', 0)\n",
    "if img is None:\n",
    "    raise Exception(\"we need the digits.png image from samples/data here !\")\n",
    "    \n",
    "cells = [np.hsplit(row,100) for row in np.vsplit(img, 50)]\n",
    "\n",
    "# First half is trainData, remaining is testData\n",
    "train_cells = [ i[:50] for i in cells ]\n",
    "test_cells  = [ i[50:] for i in cells]\n",
    "deskewed    = [list(map(deskew, row)) for row in train_cells]\n",
    "hogdata     = [list(map(hog, row)) for row in deskewed]\n",
    "trainData   = np.float32(hogdata).reshape(-1,64)\n",
    "responses   = np.repeat(np.arange(10),250)[:, np.newaxis]\n",
    "\n",
    "svm = cv.ml.SVM_create()\n",
    "svm.setKernel(cv.ml.SVM_LINEAR)\n",
    "svm.setType(cv.ml.SVM_C_SVC)\n",
    "svm.setC(2.67)\n",
    "svm.setGamma(5.383)\n",
    "svm.train(trainData, cv.ml.ROW_SAMPLE, responses)\n",
    "svm.save('svm_data.dat')\n",
    "\n",
    "deskewed = [list(map(deskew,row)) for row in test_cells]\n",
    "hogdata  = [list(map(hog,row)) for row in deskewed]\n",
    "testData = np.float32(hogdata).reshape(-1, bin_n * 4)\n",
    "result   = svm.predict(testData)[1]\n",
    "mask     = result == responses\n",
    "correct  = np.count_nonzero(mask)\n",
    "\n",
    "print(correct * 100.0 / result.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 특별한 기술은 거의 94 %의 정확성을주었습니다. 더 높은 정확도가 가능한지 확인하기 위해 SVM의 다양한 매개 변수에 대해 다른 값을 시도 할 수 있습니다. 또는이 분야의 기술 자료를 읽고이를 구현할 수 있습니다.\n",
    "\n",
    "#### Additional Resources\n",
    "1. [지향성 그라디언트 비디오의 히스토그램](https://www.youtube.com/watch?v=0Zib1YEE4LU)\n",
    "\n",
    "#### Exercises\n",
    "OpenCV 샘플에는 개선 된 결과를 얻기 위해 위의 방법을 약간 개선 한 digits.py가 포함되어 있습니다. 또한 참조를 포함합니다. 그것을 확인하고 이해하십시오."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "249.261px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
